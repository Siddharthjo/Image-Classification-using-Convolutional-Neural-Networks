{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMJRlAovDXIP"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load the dataset from Keras datasets module\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_X, train_Y), (test_X, test_Y) = cifar10.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Plot some images from the dataset to visualize the dataset\n",
        "\n",
        "n = 6\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(n):\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    plt.imshow(train_X[i])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "tAkkXs2zDwAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Import the required layers and modules to create our convolution neural net architecture\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n"
      ],
      "metadata": {
        "id": "iNdvr_tRDwDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Convert the pixel values of the dataset to float type and then normalize the dataset\n",
        "\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n",
        "\n"
      ],
      "metadata": {
        "id": "DkHBRqTUDwHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Now perform the one-hot encoding for target classes\n",
        "\n",
        "train_Y = np_utils.to_categorical(train_Y)\n",
        "test_Y = np_utils.to_categorical(test_Y)\n",
        "\n",
        "num_classes = test_Y.shape[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "Sz7wc3DSDwJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create the sequential model and add the layers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "ai01WptZDwM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Configure the optimizer and compile the model\n",
        "\n",
        "sgd = SGD(lr=0.01, momentum=0.9, decay=(0.01/25), nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "xLqmlbcPDwPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: View the model summary for better understanding of model architecture\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "xC1_xoQxDwTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Train the model\n",
        "\n",
        "model.fit(train_X, train_Y, validation_data=(test_X, test_Y), epochs=10, batch_size=32)\n",
        "\n"
      ],
      "metadata": {
        "id": "dHUG8VNgDwVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Calculate its accuracy on testing data\n",
        "\n",
        "_, acc = model.evaluate(test_X, test_Y)\n",
        "print(\"Accuracy on testing data:\", acc * 100)\n",
        "\n"
      ],
      "metadata": {
        "id": "mXS1dEpvDwZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Save the model\n",
        "\n",
        "model.save(\"model1_cifar_10epoch.h5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AEU3PR1_FIAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Make a dictionary to map to the output classes and make predictions from the model\n",
        "\n",
        "results = {\n",
        "    0: 'aeroplane',\n",
        "    1: 'automobile',\n",
        "    2: 'bird',\n",
        "    3: 'cat',\n",
        "    4: 'deer',\n",
        "    5: 'dog',\n",
        "    6: 'frog',\n",
        "    7: 'horse',\n",
        "    8: 'ship',\n",
        "    9: 'truck'\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "GK5rHdqeFICi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of making predictions on a custom image\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "im = Image.open(\"__image_path__\")\n",
        "\n",
        "# Resize the image to match dataset shape\n",
        "im = im.resize((32, 32))\n",
        "\n",
        "# Expand dimensions to fit model input shape\n",
        "im = np.expand_dims(im, axis=0)\n",
        "\n",
        "# Convert to numpy array\n",
        "im = np.array(im)\n",
        "\n",
        "# Make prediction\n",
        "pred = model.predict_classes([im])[0]\n",
        "print(\"Predicted class:\", results[pred])\n"
      ],
      "metadata": {
        "id": "7F-Y3IR7FIGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DBOgP0_fFIIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WjClwc7sFIMd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}